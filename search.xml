<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[奇异值分解]]></title>
    <url>%2Fblog%2F2019%2F08%2F17%2F%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[奇异值分解（SVD）的原理与在降维中的应用 总结原理并讨论在PCA降维算法中如何运用SVD 特征值和特征向量定义如下： $Ax=\lambda x$其中$A$是一个$n\times n$的矩阵，即是个方阵；x是一个n维向量。我们可以将矩阵A特征分解，如果我们求出来矩阵A的n个特征值，$\lambda_1 \leq \lambda_2\leq,\dots ,\lambda_n$以及这n个特征值所对应的特征向量$\{ w_1,w_2,\dots,w_n \}$如果这n个特征向量线性无关，则矩阵A就能对角化，表示为：$W^{-1}AW=\Sigma$所以得到$ A=W\Sigma W^{-1}$W是n个特征向量张成的$n\times n$维矩阵，$\Sigma$为主对角线为特征值的对角矩阵。一般会把W这n个特征向量标准化，即满足$||w_i||_2=1$,或者说$w_{i}^{T}w_i=1$,此时W的n个特征向量为标准正交基，满足$W^TW=I$，即$W^T=W^{-1}$，也就是W是酋矩阵 这样得到特征分解表达式： $A=W\Sigma W^T$ 注意：特征分解，矩阵A必须是方阵 SVD 奇异值分解如果A不是方阵，采用奇异值分解 假定矩阵A是一个$m\times n$的矩阵，定义矩阵A的SVD分解为：$A=U\Sigma V^T$其中U是一个$m\times n$的矩阵，$\Sigma$是一个$m\times n$的矩阵，是对角矩阵，即除对角线元素以外全为0，主对角线上的每个元素都称为奇异值，V是一个$n\times n$的矩阵。U和V都是酋矩阵，即满足$U^TU=I,V^TV=I$。如果将A的转置和A做矩阵乘法，就会得到一个$n\times n$的方阵：$A^TA$。就可以对这个方阵做特征值分解，满足：$(A^TA)v_i=\lambda_iv_i$将$A^TA$的所有特征向量张成一个$n\times n$的酋矩阵V，一般称V的特征向量为右奇异值向量同理：将A和A的转置做矩阵乘法，得到一个$m\times m$的方阵：$AA^T$。其这个方阵进行特征分解，得到一个$m\times m$的酋矩阵U，称为左奇异值向量。 $A=U\Sigma V^T\Longrightarrow AV=U\Sigma V^TV \Longrightarrow AV = U\Sigma \Longrightarrow Av_i=\sigma_iu_i \Longrightarrow \sigma_i=\frac{Av_i}{u_i}$ 其实也是 $U^TAV=\Sigma$ 证明： 以V矩阵为例： $A=U\Sigma V^T \Longrightarrow A^T=V\Sigma ^TU^T \Longrightarrow A^TA=V\Sigma ^TU^TU\Sigma V^T=V\Sigma ^2V^T$ 其中：$U^TU=I,\Sigma ^T\Sigma=\Sigma^2$ $AA^T,A^TA$的特征值等于奇异值的平方。奇异值矩阵中，前10%或者1%的奇异值的和就占据了全部奇异值之和的99%。所以可以用k个奇异值和对应的左右奇异值向量来近似描述矩阵。]]></content>
      <categories>
        <category>优化求解</category>
      </categories>
      <tags>
        <tag>奇异值分解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-next博客搭建3-部署]]></title>
    <url>%2Fblog%2F2019%2F08%2F17%2Fhexo-next%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA3%2F</url>
    <content type="text"><![CDATA[当我们在本地运行好博客时，可以将它部署到免费的公共仓库来实现在线查看，主要的仓库网站有github和码云。github由于是美国网站，我们学校的网络push代码很慢，所以我选择了国内的网站码云。以下是码云的部署过程，github与之类似。 申请Gitee账号创建项目并设置首先新建仓库 然后进行如下设置 在站点配置文件_config.yml中配置Git1234deploy: type: git repo: https://gitee.com/QiangHaopeng/blog.git #上图中3的链接 branch: master 注意： 冒号后面要有空格 发布到Giteegit bash中输入1234npm install hexo-deployer-git --save #安装自动部署发布工具hexo cleanhexo g #生成hexo d #利用git将静态网站推送到Gitee的仓库中 首次发布需要输入Gitee的账号和密码 Gitee的pages服务开启选择仓库的服务 然后开启pages服务 首次是开启，得到得到自己的博客链接http://qianghaopeng.gitee.io/blog 在站点配置文件_config.yml中配置博客地址12url: http://qianghaopeng.gitee.io/blogroot: /blog 再执行命令：123hexo cleanhexo g #生成hexo d #利用git将静态网站推送到Gitee的仓库中 然后更新Gitee Pages过一段就能在自己的博客链接看到自己的博客主页了。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-next博客搭建2-设置]]></title>
    <url>%2Fblog%2F2019%2F08%2F17%2Fhexo-next%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA2%2F</url>
    <content type="text"><![CDATA[主要一些功能的实现，包括： 插入本地图像 latex公式显示 阅读时长加字数统计 代码块设置 打赏功能 评论功能 分享功能 等等 添加图像 首先站点配置文件里面的post_asset_folder设置为true 在git bash输入npm install hexo-asset-image --save 之后在生成博文的时候，默认也会在/source/_posts中生成一个同名的文件夹，把图片放到对应的文件夹下，采用1&#123;% asset_img 图像名 图像描述 %&#125; 第二个方案就是采用图床，可以用路过图床或者七牛，生成图像外链，采用markdown语法引用即可。 latex公式显示 更换hexo的渲染引擎 12npm uninstall hexo-renderer-markednpm install hexo-renderer-kramed --save 进入next的配置文件，打开mathjax开关，设置为true 解决语义冲突，在hexo的目录找到node_modules\kramed\lib\rules\inline.js，在该文件中找到escape和em字段进行如下修改：12escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 这样就可以使用latex公式了。 文章内超链接文本样式要求：超链接文本与普通文字区分在themes\next\source\css\_common\components\post\post.styl中最后部分添加如下代码：12345678910.post-body p a&#123;color: #0593d3; //原始链接颜色border-bottom: none;border-bottom: 1px solid #0593d3; //底部分割线颜色&amp;:hover &#123;color: #fc6423; //鼠标经过颜色border-bottom: none;border-bottom: 1px solid #fc6423; //底部分割线颜色&#125;&#125; 文章底部注释版权直接采用next的主题配置文件中，定位到creative_commons下的post，将false改成true 添加阅读时长和字数 安装hexo-symbols-count-time 1npm install hexo-symbols-count-time 配置hexo，在站点配置文件末尾添加： 12345symbols_count_time: symbols: true #字数 time: true #阅读时长 total_symbols: true # 所有文章总字数 total_time: true #总时长 配置next，修改主题配置设置文件： 123456789101112131415symbols_count_time: separated_meta: true item_text_post: true item_text_total: true awl: 4 wpm: 275 busuanzi_count: enable: true total_visitors: true total_visitors_icon: user total_views: true total_views_icon: eye post_views: true post_views_icon: eye 重启hexo服务 hexo首页文章显示一部分在文章中添加&lt;!--more--&gt;标记，只显示标记之前的内容。 代码块设置一共5种样式：normal，night，night blue， night eighties在主题配置文件中highlight_theme设置，同时设置复制按钮，在copy_button.enable中设置true，show_result中设置true 标签设置不喜欢#标签，可以设置tag_icon: true,还可以启用标签云, tagcloud为true 打赏将图片放在images，设置Reward中微信或者支付宝。 侧栏中显示进度条1234back2top: enable: true #打开后默认在右侧 # Back to top in sidebar. sidebar: true #打开后在侧栏 分享功能添加addthis，具体操作请参看博客(https://jasonssun.github.io/2019/06/15/Hexo搭建博客NexT主题之AddThis分享文章的配置/)，但是他的稍微有点问题，最后的配置规则部分可以不设置，得到了代码配置就好了，若设置规则，可能会有问题。 评论功能这里我使用的来比力，进入该网站注册账号，登录后选择上方关键字安装，选择免费版本，然后会得到来比力city版安装代码在主题配置文件中查找关键字livere_uid，将data-uid等号后面，引号之中的内容复制到过来，注意如果有==，要删除。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>功能实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+next博客搭建-安装]]></title>
    <url>%2Fblog%2F2019%2F08%2F16%2Fhexo-next%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA1%2F</url>
    <content type="text"><![CDATA[前言在一天逛B站的时候，看到了羊哥（codesheep）发布的“手把手教你从0开始搭建自己的个人博客 |无坑版视频教程| hexo”视频，链接：https://www.bilibili.com/video/av44544186?t=583 。就根据视频进行了博客系统的搭建。 经过查阅其他的人的博客系统以及自己的摸索，自己使用hexo+next来搭建。也可以根据Next官方文档配置（https://theme-next.org/docs/getting-started/） 安装nodejs 和 git windows10可以直接在nodejs官方下载，以及git工具。如图 Ubuntu18.04可以直接sudo apt install nodejs来下载(ubuntu配置博客功能时有问题，我没时间再搞，以下主要是win10平台) 安装好之后，新建一个文件夹专门用来存放自己的blog系统，这样即使自己搞坏了博客系统配置，也可以删除该文件夹，重新配置blog，丝毫不会影响电脑中的其他文件。例如我新建了E:/MyBlog文件，进入文件右键点击 git bash here, 进入控制台，可以输入node -v和npm -v来查看node版本，可以时常通过pwd来确定自己所在路径，确保在MyBlog目录下。 更换淘宝源直接采用npm下载很慢，我们通过换用淘宝源来下载hexo代码： 1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装完成可利用cnpm -v查看版本号输入cnpm install -g hexo-cli来安装hexo，完成之后hexo -v检查版本号 初始化blog系统在MyBlog文件夹下输入hexo init来初始化博客系统。 遇到的问题：git clone特别慢 解决办法：修改hosts文件。windows下：用编辑器打开host文件： C:\Windows\System32\drivers\etc\hosts， 在hosts文件末尾添加下面两个地址; Ubuntu下同理，sudo gedit /etc/hosts打开hosts，添加下面两个地址，sudo /etc/init.d/networking restart重新载入hosts12151.101.72.249 github.global.ssl.fastly.net192.30.253.112 github.com 从而初始化得到博客系统。以下一些在git bash中操作指令123hexo clean #清理hexo中生成的博客文件，用来初始化一下hexo g #生成博客文件hexo s #开启博客服务，本地可以在`localhost:4000`来访问，`ctrl+c`终止博客服务。 特别提醒：Ubuntu尽可能在管理员下操作，sudo su从而保证权限。 配置主题在MyBlog文件夹下的git bash输入git clone https://github.com/theme-next/hexo-theme-next themes/next，从而clone下来next主题文件。我们的优化都是基于next主题进行的。首先在站点配置文件MyBlog/_config.yml设置，可以利用nodepad++或者其他开发工具打开该配置文件，进行如下设置 然后配置主题配置themes/next/_config.yml: 修改站点图标 可以自己找的图像ps成16*16，32*32各1张，放到路径themes/next/source/images下。特别注意涉及到主题一些图像的变换，一般都是放到主题下面的这个文件夹中，在配置文件的路径填写时下/images/图像名即可 个人链接 个人的一些社交媒体的账号展示 个人头像 同理，将自己的头像放到next/source/images下. 主页显示的标识 主页显示的标识。同时，next下有四个主题，在172到176行可以选择，我选择的第四个，所以直接把注释#去掉即可。 效果展示 此时点击关于、标签、归类时，显示是空界面，因为我们没创建。 bash或者git bash执行：hexo new page categories，在MyBlog的文件source就会多出来一个categories文件夹，打开该文件夹，其中的index.md写入： 12345---title: 分类date: 2019-08-16 18:11:08type: &quot;categories&quot;--- 三个短线表示md文件的标记，其中日期不用管，主要更改title，以及type，将其值设置为”categories”，注意，冒号之后都要有空格。 同样方法更改bags：hexo new page tags，type设置为tags。 特别注意：此后写的博客中的标签和分类都会自动归档到分类和标签中。但是要在博客的md文件中声明分类和标签。每次都去写声明很麻烦，我们可以在MyBlog/scaffolds/post.md中设置好模板。输入： 123456---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:categories:--- 写第一篇博客在MgBlog文件夹下的git bash 运行hexo n 博客名 我们的博客的md文件其实都存放在Myblog/source/_posts中，我们在刚生成的md文件中书写博客，运行hexo g和hexo s就可以在本地的浏览器localhost:4000中查看。如果我们不想要这篇博客了，直接删除该文件夹中该博客的.md文件即可。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>nodejs</tag>
        <tag>gitclone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Word Embedding介绍]]></title>
    <url>%2Fblog%2F2019%2F08%2F15%2Fembedding%2F</url>
    <content type="text"><![CDATA[文本特征选择就是在训练集中选择一个词汇子集的过程。 现在的方法不能直接处理文本数据，通过Word Embedding的方法将文本数据转化为数值型数据。如果将word看作文本的最小单元，可以将Word Embedding理解为一种映射，或者说是嵌入（embedding）到一个数值向量空间。之所以称之为Embedding，因为这种方法往往伴随着一种降维的思想。 就是把one-hot编码的词嵌入到一个低维空间。 常用的文本特征选择方法有 词频法 TF 词频逆文档频率法 TF-IDF 信息增益 IG 互信息 MI TF 和 IDF都是在不考虑分类分布的情况下消除低频词 Word Embedding的输入Word Embedding的输入是原始文本中一组不重叠的词汇，假设有句子：apple on a apple tree 为了方便处理，把这些词汇放在一个dictionary：[apple, on, a, tree] ，这个dictionary可以看做wordEmbedding的输入 Word Embedding的输出就是每一word的向量表示，最简单的方式就是one-hot编码方式，那么每一word都对应了一种数值表示。 apple对应的vector就是[1,0,0,0] a对应的是[0,0,1,0] Word Embedding的类型主要有两种： 基于频率 基于预测 基于频率的Word Embedding基于频率的Word Embedding又可以分为： Count Vector TF—IDF Vector Co-Occurence Vector 其本质都是基于one-hot，以频率为主的加权。 Count Vector假设有一个语料库C，其中有D个文档：$d_1,d_2,\dots,d_D$,$C$中一共有$N$个word，这$N$个word构成原始输入的dictionary，据此可以生成一个矩阵M，其规模为$D\times N$ 例子： 语料库内容如下： D1：He is a boy D2：She is a girl，good girl 那么可以构造一个$2\times 7$的矩阵 He She is a boy girl good D1 1 0 1 1 1 0 0 D2 0 1 1 1 0 2 1 每个文档用词向量来表示，那么dictionary很庞大，矩阵是稀疏的，大量的无用信息。通常的做法是选取出现次数最频繁的那些词来构建dictionary，例如top10000 TF-IDF上面的只考虑到了词频TF，也就是词在文档中出现的频率。TF越大，说明词在本文档中的重要性越高，对应的权重也就越高。这个思路大体上来说是对的，例如，对于一个主题是Cat的文档，显然Cat这个词汇在本文档中的出现频率会相对高。 但如果我们把视野扩展到整个语料库，会发现，像is，a等通用词汇，几乎在每个文档里出现的频率都很高。由此，我们可以得到这样的结论：对于一个word，如果在特定文档里出现的频率高，而在整个语料库里出现的频率低，那么这个word对于该文档的重要性就比较高。因此我们可以引入逆文档频率IDF（Inverse Document Frequency）的概念： ​ $IDF = log(N/n)$ N代表语料库中文档的总数，n代表某个word在n个文档中出现过。 因此当一个word出现的频繁，那么IDF就越小。IDF用来惩罚常用词汇，TF用来奖励那么特定文档中出现频繁的词汇。用$TF \times IDF$来表示词汇的权重，这样可以提取出来文档的关键词。 对于一个word， 如果在特定文档里出现的频率高，即TF较大，则反映出了该word在自己的文档中可能是比较关键的词。 在整个语料库里出现的频率低，即IDF较小，则排除了常用词的干扰。 例子： 语料库共有2个文档，其中一个文档名为d，且文档d一共有8个词汇。 cat只出现在文档d中，出现过4次； is在两个文档中都有出现，在d中出现了4次。 那么对于文档d进行提取关键词： $TF(‘cat’, d) = \frac{4}{8} = 0.5$ $TF(‘is’, d) = \frac{4}{8} = 0.5$ $IDF(‘cat’, d) = log(\frac21) = 0.301$ $IDF(‘is’, d) = log(\frac22) = 0$ 那么计算TF-IDF $TFIDF(‘cat’, d) = 0.5 \times 0.301 = 0.15$ $TFIDF(‘is’, d) = 0$ 这样就能找出来文件的关键词汇。 Co-Occurence Vector自然语言一大特色是语义和上下文。有如下著名的研究结果：相似的单词趋向于有相似的上下文(context)。举例： 那个人是个男孩 那个人是个女孩 Context Window 上下文窗口，需要定义其长度。例如： 定义窗口大小为2，则such的Context Window如图所示。 Co-Occurence（共现） 对于such这个单词来说，在其上下文窗口内，它分别与[she, is, a, beautiful]这四个单词各出现了一次共现。如果我们在语料库中所有such出现的地方，计算其共现的单词，并按次数累加，那么我们就可以利用其上下文范围内的单词来表示such这个词，这就是Co-Occurence Vector的计算方法。 假定有如下语料库： He is not lazy. He is intelligent. He is smart. 当窗口大小为2的时候，可以得到如下共现矩阵： 计算过程如图所示： 这种方法可以保留语义信息。 基于预测的Word Embedding算法满足 携带上下文信息 词的表示是稠密的 算法主要有CBOW和Skip-Gram CBOW （continues bag of words）本质是通过context来预测word 如图所示： 首先语料库内的每一word都可以用one-hot编码，假设选取context window为2，那么模型中的一对input和target就是： input：He 和 is 的one-hot编码 target：a 的 one-hot编码 算法步骤： 窗口大小为C/2，W：$V\times N$， $V =( \sum_{i=0}^{C} W\times C_i)/C$ 最终网络输出层才用softmax，即计算概率，与a 的one-hot编码作对比。该方法关注点在于hidden layer的输出，因此word是one-hot编码， 1234import tensorflow as tfhello = tf.constance('Hello Google!')sess = tf.Session()print(sess.run(hello))]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>embedding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F2019%2F08%2F15%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
